{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 4 Assignment - SVMs, Trees, RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "The goal of this homework is to review and bring together what we have learned about Support Vector Machines, Decision Trees, Random Forests, and ensembles. \n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:30PM on Wednesday, February 17.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "Use the cancer_uci.csv dataset in the Data directory of our course repo. This is the [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)) dataset from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Load the data and check for balance between the two classes. If the ratio is less than 60/40 rebalance the classes to 50/50. We've provided some help here to get you started.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign       458\n",
       "Malignant    241\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "canc = pd.read_csv(\"../data/cancer_uci.csv\", index_col=0)\n",
    "canc.head()\n",
    "canc.Class.value_counts()\n",
    "# What are the frequencies of each class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced classes so we need to decide if we want to undersample, and take only 241 values from the Benign category, or oversample, and artificially inflate the volume of malignant data. First, let's convert to binary 1,0 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    458\n",
       "1    241\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canc.Class = canc.Class.map({'Benign':0,'Malignant':1})\n",
    "canc.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undersample, we would throw away almost half of our benign examples, which would greatly alter our dataset and we don't want to lose that much info. So let's oversample! Here is a pattern for how to oversample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "# Separate your two classes:\n",
    "mal_example = canc[canc.Class == 1]\n",
    "benign_example = canc[canc.Class == 0]\n",
    "\n",
    "# Oversample the malignant class to have a 50/50 ratio:\n",
    "mal_over_example = mal_example.sample(458,replace=True)\n",
    "\n",
    "# Recombine the two frames:\n",
    "over_sample = pd.concat([mal_over_example,benign_example])\n",
    "\n",
    "# Sanity check the length:\n",
    "print len(over_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Are the features normalized? If not, use the scikit-learn standard scaler to normalize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 916 entries, 263 to 695\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             916 non-null int64\n",
      "Clump_Thickness                916 non-null int64\n",
      "Uniformity_of_Cell_Size        916 non-null int64\n",
      "Uniformity_of_Cell_Shape       916 non-null int64\n",
      "Marginal_Adhesion              916 non-null int64\n",
      "Single_Epithelial_Cell_Size    916 non-null int64\n",
      "Bare_Nuclei                    916 non-null object\n",
      "Bland_Chromatin                916 non-null int64\n",
      "Normal_Nucleoli                916 non-null int64\n",
      "Mitoses                        916 non-null int64\n",
      "Class                          916 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 85.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "# review data for null values and replace\n",
    "over_sample.info()\n",
    "\n",
    "# convert Bare_Nuclei to numeric\n",
    "over_sample.Bare_Nuclei = over_sample.Bare_Nuclei.convert_objects(convert_numeric=True)\n",
    "\n",
    "# fill null values with imputed mean and standard deviation\n",
    "# over_sample.Bare_Nuclei[over_sample.Bare_Nuclei.notnull()].describe()\n",
    "over_sample.Bare_Nuclei.fillna(np.random.normal(4.636, 3.962), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# assign features and target\n",
    "features = over_sample.drop(['Class', 'Sample_code_number'], axis = 1)\n",
    "target = over_sample.Class\n",
    "\n",
    "# standardize the features\n",
    "scaler = StandardScaler()\n",
    "scal_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Train a linear SVM, using the cross validated accuracy as the score (use the scikit-learn method).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978225035834\n"
     ]
    }
   ],
   "source": [
    "# import relevant libraries\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# train the model and make predictions using scal_features\n",
    "svc_X_train, svc_X_test, svc_y_train, svc_y_test = train_test_split(scal_features, target, test_size = 0.2, random_state=1)\n",
    "\n",
    "model_svc = SVC(C=1, kernel='linear', probability = True).fit(svc_X_train, svc_y_train) # linear model\n",
    "print cross_val_score(SVC(C=1,kernel='linear', probability = True), scal_features, target, cv=5).mean() # cross validated score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Display the confusion matrix, classification report, and AUC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91  4]\n",
      " [ 0 89]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        95\n",
      "          1       0.96      1.00      0.98        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       184\n",
      "\n",
      "0.994559432289\n"
     ]
    }
   ],
   "source": [
    "# import relevant libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "svc_preds = model_svc.predict(svc_X_test)\n",
    "print metrics.confusion_matrix(svc_y_test, svc_preds)\n",
    "print classification_report(svc_y_test, model_svc.predict(svc_X_test))\n",
    "\n",
    "# calculate SVC linear predicted probability of test features and use to generate AUC\n",
    "model_svc_predicted_proba = model_svc.predict_proba(svc_X_test)\n",
    "svc_fpr, svc_tpr, svc_thresholds = roc_curve(svc_y_test, model_svc_predicted_proba[:, 1])\n",
    "svc_roc_auc = auc(svc_fpr, svc_tpr)\n",
    "print svc_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Repeat steps 2 through 4 using a Decision Tree model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962924032489\n",
      "[[92  3]\n",
      " [ 1 88]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98        95\n",
      "          1       0.97      0.99      0.98        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       184\n",
      "\n",
      "0.978592548788\n"
     ]
    }
   ],
   "source": [
    "# train and predict using Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# train the model and make predictions using scal_features\n",
    "tree_X_train, tree_X_test, tree_y_train, tree_y_test = train_test_split(scal_features, target, test_size = 0.2, random_state=1)\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=1)\n",
    "model_tree.fit(tree_X_train, tree_y_train)\n",
    "\n",
    "print cross_val_score(model_tree, scal_features, target, cv=5).mean() # cross validated score\n",
    "\n",
    "# print confusion matrix and classification report\n",
    "tree_preds = model_tree.predict(tree_X_test)\n",
    "print metrics.confusion_matrix(tree_y_test, tree_preds)\n",
    "print classification_report(tree_y_test, model_tree.predict(tree_X_test))\n",
    "\n",
    "# calculate decision tree predicted probability of test features and use to generate AUC\n",
    "model_tree_predicted_proba = model_tree.predict_proba(tree_X_test)\n",
    "tree_fpr, tree_tpr, tree_thresholds = roc_curve(tree_y_test, model_tree_predicted_proba[:, 1])\n",
    "tree_roc_auc = auc(tree_fpr, tree_tpr)\n",
    "print tree_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above scores, the Decision Tree model does not perform quite as well as the SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Repeat steps 2 through 4 using a Random Forest model. Are the results better or worse than the SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981473960822\n",
      "[[92  3]\n",
      " [ 0 89]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98        95\n",
      "          1       0.97      1.00      0.98        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       184\n",
      "\n",
      "0.993554109994\n"
     ]
    }
   ],
   "source": [
    "# train and predict using Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train the model and make predictions using scal_features\n",
    "forest_X_train, forest_X_test, forest_y_train, forest_y_test = train_test_split(scal_features, target, test_size = 0.2, random_state=1)\n",
    "\n",
    "# initialize a random forest classifier, fit the forest to the training set, and make predictions\n",
    "model_forest = RandomForestClassifier(random_state = 1) \n",
    "model_forest.fit(forest_X_train, forest_y_train)\n",
    "forest_preds = model_forest.predict(forest_X_test)\n",
    "\n",
    "print cross_val_score(model_forest, scal_features, target, cv=5).mean()\n",
    "\n",
    "# print confusion matrix and classification report\n",
    "forest_preds = model_forest.predict(forest_X_test)\n",
    "print metrics.confusion_matrix(forest_y_test, forest_preds)\n",
    "print classification_report(forest_y_test, model_forest.predict(forest_X_test))\n",
    "\n",
    "# calculate randome forest predicted probability of test features and use to generate AUC\n",
    "model_forest_predicted_proba = model_forest.predict_proba(forest_X_test)\n",
    "forest_fpr, forest_tpr, forest_thresholds = roc_curve(forest_y_test, model_forest_predicted_proba[:, 1])\n",
    "forest_roc_auc = auc(forest_fpr, forest_tpr)\n",
    "print forest_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above scores, the Random Forest model performs slightly better than the SVM model (cross-val score slightly better and AUC in-line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Questions\n",
    "**The following questions are strongly encouraged, but not required for this homework assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Combine the SVM and the Decision Tree model using the [Voting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html). Are the results better than either of these base classifiers alone?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Train an SVM using the RBF kernel. Is this model better or worse?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
